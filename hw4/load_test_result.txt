Overall information:
    Server Software:
    Server Hostname:        192.168.162.162
    Server Port:            8000

    Document Path:          /
    Document Length:        4537 bytes

    Concurrency Level:      30

Basic server:
    Time taken for tests:   0.184 seconds
    Complete requests:      1000
    Failed requests:        0
    Total transferred:      4603000 bytes
    HTML transferred:       4537000 bytes
    Requests per second:    5431.51 [#/sec] (mean)
    Time per request:       5.523 [ms] (mean)
    Time per request:       0.184 [ms] (mean, across all concurrent requests)
    Transfer rate:          24415.26 [Kbytes/sec] received

    Connection Times (ms)
                min  mean[+/-sd] median   max
    Connect:        0    1   0.8      0       4
    Processing:     0    5   2.3      5      11
    Waiting:        0    4   2.5      4      11
    Total:          1    5   1.8      5      11
    WARNING: The median and mean for the initial connection time are not within a normal deviation
            These results are probably not that reliable.

    Percentage of the requests served within a certain time (ms)
    50%      5
    66%      6
    75%      7
    80%      7
    90%      8
    95%      9
    98%      9
    99%     10
    100%     11 (longest request)

Fork server:
    The fork server could not handle any more requests than 1000 and any higher concurrency than 30, or else it throws an error "Too many open files" at the time that a connection request is accepted and a client socket is created. The cause is probably the latency in forking/scheduling/completing a child process: a high latency means that so many child processes are unfinished and hence occupying a socket position, that the # of open sockets exceeded the maximum # of files allowed to be open at the same time. If we can't control the concurrency of the request, then we either need to bring down the forking/scheduling overhead, add more processing units to the machine, or change to a non-forking workflow.

    Time taken for tests:   0.407 seconds
    Complete requests:      1000
    Failed requests:        0
    Total transferred:      4603000 bytes
    HTML transferred:       4537000 bytes
    Requests per second:    2458.22 [#/sec] (mean)
    Time per request:       12.204 [ms] (mean)
    Time per request:       0.407 [ms] (mean, across all concurrent requests)
    Transfer rate:          11050.00 [Kbytes/sec] received

    Connection Times (ms)
                min  mean[+/-sd] median   max
    Connect:        0    0   2.1      0      14
    Processing:     0   11   4.4     11      43
    Waiting:        0   11   4.4     11      42
    Total:          3   12   4.5     11      43

    Percentage of the requests served within a certain time (ms)
    50%     11
    66%     12
    75%     14
    80%     15
    90%     19
    95%     20
    98%     23
    99%     25
    100%     43 (longest request)

Thread server:
    Time taken for tests:   0.233 seconds
    Complete requests:      1000
    Failed requests:        0
    Total transferred:      4603000 bytes
    HTML transferred:       4537000 bytes
    Requests per second:    4286.42 [#/sec] (mean)
    Time per request:       6.999 [ms] (mean)
    Time per request:       0.233 [ms] (mean, across all concurrent requests)
    Transfer rate:          19267.95 [Kbytes/sec] received

    Connection Times (ms)
                min  mean[+/-sd] median   max
    Connect:        0    1   1.2      1       5
    Processing:     0    6   4.9      5      33
    Waiting:        0    5   4.7      3      32
    Total:          1    7   4.7      6      33

    Percentage of the requests served within a certain time (ms)
    50%      6
    66%      7
    75%      8
    80%      9
    90%     12
    95%     16
    98%     25
    99%     27
    100%     33 (longest request)

Pool server (#threads = 5):
    Time taken for tests:   0.146 seconds
    Complete requests:      1000
    Failed requests:        0
    Total transferred:      4603000 bytes
    HTML transferred:       4537000 bytes
    Requests per second:    6849.46 [#/sec] (mean)
    Time per request:       4.380 [ms] (mean)
    Time per request:       0.146 [ms] (mean, across all concurrent requests)
    Transfer rate:          30789.11 [Kbytes/sec] received

    Connection Times (ms)
                min  mean[+/-sd] median   max
    Connect:        1    2   0.9      2       7
    Processing:     0    2   0.8      2       7
    Waiting:        0    1   0.8      1       6
    Total:          3    4   1.2      4       9

    Percentage of the requests served within a certain time (ms)
    50%      4
    66%      4
    75%      5
    80%      5
    90%      6
    95%      7
    98%      8
    99%      8
    100%      9 (longest request)

Pool server (#threads = 15):
    Time taken for tests:   0.152 seconds
    Complete requests:      1000
    Failed requests:        0
    Total transferred:      4603000 bytes
    HTML transferred:       4537000 bytes
    Requests per second:    6590.83 [#/sec] (mean)
    Time per request:       4.552 [ms] (mean)
    Time per request:       0.152 [ms] (mean, across all concurrent requests)
    Transfer rate:          29626.55 [Kbytes/sec] received

    Connection Times (ms)
                min  mean[+/-sd] median   max
    Connect:        1    2   1.1      2      10
    Processing:     1    2   1.2      2      15
    Waiting:        0    1   1.1      1      12
    Total:          2    4   1.7      4      17

    Percentage of the requests served within a certain time (ms)
    50%      4
    66%      4
    75%      5
    80%      5
    90%      5
    95%      6
    98%     12
    99%     13
    100%     17 (longest request)

Analysis:
    Basic server:
        Time per request:       5.523 [ms] (mean)
        Time per request:       0.184 [ms] (mean, across all concurrent requests)

    Fork server:
        Time per request:       12.204 [ms] (mean)
        Time per request:       0.407 [ms] (mean, across all concurrent requests)

    Thread server:
        Time per request:       6.999 [ms] (mean)
        Time per request:       0.233 [ms] (mean, across all concurrent requests)

    Pool server (#threads = 5):
        Time per request:       4.380 [ms] (mean)
        Time per request:       0.146 [ms] (mean, across all concurrent requests)

    Pool server (#threads = 15):
        Time per request:       4.552 [ms] (mean)
        Time per request:       0.152 [ms] (mean, across all concurrent requests)

Conclusion:
    Delegating the heavy lifting to a worker thread/process doesn't automatically mean better performance than a single-process/thread basic server. When the overhead of such delegation is non-neligible, such as in the case of the fork server, the performance actually deteriorated due to the high load, and was causing fatal errors much earlier than the other servers.

    The best performance came from servers that have a persisted pool of worker threads, thus preventing incurring overhead in line with the client request. And lastly, creating even more threads in the pool (5 -> 15) doesn't bring a siignificant improvement here, possibly due to the low concurrency and request count, but also could be due to thread competence because of the use of mutex lock, conditional variable, and the broadcast method on CV.